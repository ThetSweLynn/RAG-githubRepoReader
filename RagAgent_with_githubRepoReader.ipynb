{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT+X1paaHYvpur2w1jJOPv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThetSweLynn/RAG-githubRepoReader/blob/main/RagAgent_with_githubRepoReader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aug1dbw-RLhA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaMBQ1n_ttpl"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain langchain-community huggingface-hub openai google-search-results tiktoken wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\" #Put yout API key here"
      ],
      "metadata": {
        "id": "1WsaRnmduU3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, Wikipedia\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "from langchain.agents.react.base import DocstoreExplorer\n",
        "from langchain.utilities import SerpAPIWrapper"
      ],
      "metadata": {
        "id": "a6dbu4rRu36u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install chromadb pypdf sentence_transformers"
      ],
      "metadata": {
        "id": "HIfxJJ4avacY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import uuid\n",
        "from langchain import PromptTemplate\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain.document_loaders import DirectoryLoader, NotebookLoader"
      ],
      "metadata": {
        "id": "rdAlV6-9vkP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "W7LEY2grWVcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is to clone your github repo to a new folder in google drive\n",
        "\n",
        "#%%bash\n",
        "#cd /content/drive/MyDrive/\n",
        "#mkdir -p MyToDos\n",
        "#cd MyToDos\n",
        "#git clone https://github.com/ThetSweLin/MyToDos.git # Change repository url here"
      ],
      "metadata": {
        "id": "PeUYl8zNXdhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_path = \"/content/drive/MyDrive/MyToDos/MyToDos\" # Change repository path here"
      ],
      "metadata": {
        "id": "4AKN42jDYBvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured"
      ],
      "metadata": {
        "id": "5fgRUakIwx88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document # Import Document class\n",
        "\n",
        "def load_and_split_files(path):\n",
        "  extensions = ['txt', 'md', 'markdown', 'rst', 'py', 'js', 'java', 'c', 'cpp', 'cs', 'go', 'rb', 'php', 'scala', 'html', 'htm', 'xml', 'yaml', 'yml', 'ini', 'toml', 'cfg', 'conf', 'sh', 'bash', 'css', 'scss', 'sql', 'gitignore', 'dockerignore', 'editorconfig', 'dart'] # json and ipynb excluded\n",
        "\n",
        "  documents = []\n",
        "\n",
        "  for ext in extensions:\n",
        "    glob_pattern = f'**/*.{ext}'\n",
        "    try:\n",
        "      loader = DirectoryLoader(repo_path, glob=glob_pattern)\n",
        "      text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=200)\n",
        "\n",
        "      loaded_documents = loader.load() if callable(loader.load) else []\n",
        "      if loaded_documents:\n",
        "        for doc in loaded_documents:\n",
        "          # Extract text content from the document object (method may vary)\n",
        "          text_content = doc.page_content # Assuming 'page_content' holds the text\n",
        "          # Pass the text content directly to split_documents\n",
        "          split_docs = text_splitter.split_documents([Document(page_content=text_content)])\n",
        "          documents.extend(split_docs) # Use extend to add multiple documents\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error loading files with pattern '{glob_pattern}': {e}\")\n",
        "      continue\n",
        "\n",
        "  return documents\n",
        "\n",
        "# Call the function and unpack three values\n",
        "documents = load_and_split_files(repo_path)"
      ],
      "metadata": {
        "id": "Ad4elI-TYC9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(documents))\n",
        "print(documents[10])"
      ],
      "metadata": {
        "id": "nL_d9lNSI4sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.schema import Document\n",
        "\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "\n",
        "persist_directory = 'db'\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=documents,\n",
        "                                 embedding=embedding,\n",
        "                                 persist_directory=persist_directory)\n",
        "\n"
      ],
      "metadata": {
        "id": "Oqk5gSkji_Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(model_name='gpt-4')\n",
        "\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)"
      ],
      "metadata": {
        "id": "KQTzfrJFnXHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Cite sources\n",
        "\n",
        "import textwrap\n",
        "\n",
        "def wrap_text_preserve_newlines(text, width=110):\n",
        "    # Split the input text into lines based on newline characters\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Wrap each line individually\n",
        "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
        "\n",
        "    # Join the wrapped lines back together using newline characters\n",
        "    wrapped_text = '\\n'.join(wrapped_lines)\n",
        "\n",
        "    return wrapped_text\n",
        "\n",
        "def process_llm_response(llm_response):\n",
        "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ],
      "metadata": {
        "id": "GcTD_cZOYVT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Updating by adding serpAPI and wikipedia\n",
        "\n",
        "from langchain.utilities import SerpAPIWrapper\n",
        "\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"\" # Put your serp api key here"
      ],
      "metadata": {
        "id": "Y7iSAI14-yT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.tools import Tool"
      ],
      "metadata": {
        "id": "IcWo46bnoeRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to use qa_chain as a tool\n",
        "def qa_chain_tool(input_text):\n",
        "  response = qa_chain({\"query\": input_text})\n",
        "  return response['result']\n",
        "\n",
        "qa_chain_tool = Tool(\n",
        "    name=\"qa_chain\",\n",
        "    func=qa_chain_tool,\n",
        "    description=\"A tool to answer questions about the content that contains in the github repository\"\n",
        ")"
      ],
      "metadata": {
        "id": "Et4dQxQNx6pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"serpapi\", \"wikipedia\"], llm=llm)\n",
        "tools.append(qa_chain_tool)"
      ],
      "metadata": {
        "id": "KZo8yO8Oo5Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools[2].name, tools[2].description"
      ],
      "metadata": {
        "id": "pFXIVm_Upsa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
      ],
      "metadata": {
        "id": "zP_xZCinpy6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.agent.llm_chain.prompt.template"
      ],
      "metadata": {
        "id": "Rkw-weiup8O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call qa_chain_tool through the agent with the query as a string value\n",
        "agent.run({\"query\": \"What is the purpose of this repository?\"})\n",
        "\n",
        "# Process the response (optional)\n",
        "process_llm_response(response)"
      ],
      "metadata": {
        "id": "TpVYnORpnk6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q0mK3P_I3G6a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}